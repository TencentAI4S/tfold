# -*- coding: utf-8 -*-
# Copyright (c) 2023, Tencent Inc. All rights reserved.
import torch
from torch import nn

from tfold.protein import ProtStruct
from tfold.utils import cdist
from tfold.model.layer import CrossAttention, Linear, PPIEmbedding, ContactEmebedding
from tfold.model.module import OuterProductMeanSM


class MonoToMultimer(nn.Module):
    """The ligand & receptor to complex conversion network.

    Args:
        ligand_c_s: number of dimensions in single features (c_s)
        ligand_c_z: number of dimensions in pair features (c_z)
        receptor_c_s: umber of dimensions in single feature for receptor (c_s)
        receptor_c_z: number of dimensions in pair feature for receptor (c_z)
    """
    def __init__(
            self,
            ligand_c_s=256,  # number of dimensions in single features (c_s)
            ligand_c_z=128,  # number of dimensions in pair features (c_z)
            receptor_c_s=256,  # number of dimensions in single feature for receptor (c_s)
            receptor_c_z=128,  # number of dimensions in pair feature for receptor (c_z),
            use_icf=False,  # use inter-chain interface feature as extra input
            num_bins=18,
            dist_min=3.375,
            dist_max=21.375
    ):
        super().__init__()
        self.ligand_c_s = ligand_c_s
        self.ligand_c_z = ligand_c_z
        self.receptor_c_s = receptor_c_s
        self.receptor_c_z = receptor_c_z
        self.num_bins = num_bins
        self.dist_min = dist_min
        self.dist_max = dist_max
        self.bin_width = (self.dist_max - self.dist_min) / self.num_bins
        self.linear_dist_ligand = Linear(self.num_bins, self.ligand_c_z, init='zeros')
        self.linear_dist_receptor = Linear(self.num_bins, self.ligand_c_z, init='zeros')
        self.linear_sfea_ligand = Linear(self.ligand_c_s, self.ligand_c_s)
        self.linear_sfea_receptor = Linear(self.receptor_c_s, self.ligand_c_s)
        self.linear_pfea_ligand = Linear(self.ligand_c_z, self.ligand_c_z)
        self.linear_pfea_receptor = Linear(self.receptor_c_z, self.ligand_c_z)
        self.cross_attn = CrossAttention(self.ligand_c_s)
        self.opm = OuterProductMeanSM(self.ligand_c_s, self.receptor_c_s, self.ligand_c_z)
        self.use_icf = use_icf
        if self.use_icf:
            self.icf_embed_sfea = PPIEmbedding(self.ligand_c_s)
            self.icf_embed_pfea = ContactEmebedding(self.ligand_c_z)

    def forward(self, ligand_feat, receptor_feat, ic_feat=None):
        """
        Args:
            ligand_feat: ligand feat generated by PLM-based model
            receptor_feat: receptor feat generated by MSA-based model

        Returns:
            sfea_tns: single features (of the ligand-receptor chain complex) of size N x L x c_s
            pfea_tns: pair features (of the ligand-receptor chain complex) of size N x L x L x c_z
        """
        aa_seq_ligand = ligand_feat['seq']
        aa_seq_receptor = receptor_feat['seq']

        # build initial single features
        sfea_tns = self._get_sfea(ligand_feat, receptor_feat)

        # build initial pair features
        pfea_tns_lg_lg = self._get_intra_chain_pfea(aa_seq_ligand, ligand_feat, 'ligand')
        pfea_tns_rc_rc = self._get_intra_chain_pfea(aa_seq_receptor, receptor_feat, 'receptor')
        pfea_tns_lg_rc, pfea_tns_rc_lg = self._get_inter_chain_pfea(ligand_feat, receptor_feat)
        pfea_tns = torch.cat([
            torch.cat([pfea_tns_lg_lg, pfea_tns_lg_rc], dim=2),
            torch.cat([pfea_tns_rc_lg, pfea_tns_rc_rc], dim=2),
        ], dim=1)

        # build extra pair feature
        if self.use_icf and ic_feat is not None:
            ic_feat = ic_feat.to(sfea_tns.device)
            # update single and pair features with inter-chain feature
            sfea_tns += self.icf_embed_sfea(ligand_feat, receptor_feat, ic_feat)
            pfea_tns += self.icf_embed_pfea(ligand_feat, receptor_feat, ic_feat)

        return sfea_tns, pfea_tns

    def _get_sfea(self, ligand_feat, receptor_feat):
        """Get single feature."""
        sfea_tns_ligand = self.linear_sfea_ligand(ligand_feat['sfea'])
        sfea_tns_receptor = self.linear_sfea_receptor(receptor_feat['mfea'][:, 0])
        sfea_tns = self.cross_attn(sfea_tns_ligand, sfea_tns_receptor)

        return sfea_tns

    def _get_intra_chain_pfea(self, aa_seq, feature, chn_type):
        """Get intra-chain pair features."""
        cord_mat = ProtStruct.get_cb_cords(aa_seq, feature['cord'])
        dist_mat = cdist(cord_mat)
        idxs_mat = torch.clip(torch.floor(
            (dist_mat - self.dist_min) / self.bin_width).to(torch.int64), 0, self.num_bins - 1)
        onht_tns = nn.functional.one_hot(idxs_mat, self.num_bins).unsqueeze(dim=0)
        if chn_type == 'ligand':
            pfea_tns = self.linear_pfea_ligand(feature['pfea'])
            pfea_tns += self.linear_dist_ligand(onht_tns.to(torch.float32))
        elif chn_type == 'receptor':
            pfea_tns = self.linear_pfea_receptor(feature['pfea'])
            pfea_tns += self.linear_dist_receptor(onht_tns.to(torch.float32))

        return pfea_tns

    def _get_inter_chain_pfea(self, ligand_feat, receptor_feat):
        """Get inter-chain pair features."""
        pfea_tns_lgrc = self.opm(ligand_feat['sfea'], receptor_feat['mfea'])
        pfea_tns_rclg = pfea_tns_lgrc.transpose(1, 2)
        return pfea_tns_lgrc, pfea_tns_rclg
