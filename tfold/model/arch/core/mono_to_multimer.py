# -*- coding: utf-8 -*-
# Copyright (c) 2024, Tencent Inc. All rights reserved.
import torch
from torch import nn

from tfold.model.layer import Linear, PPIEmbedding, ContactEmebedding
from tfold.model.module import OuterProductMeanSM
from tfold.model.module.attention import CrossAttention
from tfold.protein import ProtStruct
from tfold.utils import cdist


class MonoToMultimerSS(nn.Module):
    """The ligand & receptor to complex conversion network.

    Args:
        ligand_c_s: number of dimensions in single features (c_s)
        ligand_c_z: number of dimensions in pair features (c_z)
        receptor_c_s: umber of dimensions in single feature for receptor (c_s)
        receptor_c_z: number of dimensions in pair feature for receptor (c_z)
    """

    def __init__(
            self,
            ligand_c_s=256,
            ligand_c_z=128,
            receptor_c_s=256,
            receptor_c_z=128,
            num_bins=18,
            dist_min=3.375,
            dist_max=21.375,
            pre_layer_norm=True
    ):
        super().__init__()
        self.ligand_c_s = ligand_c_s
        self.ligand_c_z = ligand_c_z
        self.receptor_c_s = receptor_c_s
        self.receptor_c_z = receptor_c_z
        self.num_bins = num_bins
        self.dist_min = dist_min
        self.dist_max = dist_max
        self.bin_width = (self.dist_max - self.dist_min) / self.num_bins
        self.pre_layer_norm = pre_layer_norm

        self.linear_dist_ligand = Linear(self.num_bins, self.ligand_c_z, init='zeros')
        self.linear_dist_receptor = Linear(self.num_bins, self.ligand_c_z, init='zeros')

        self.linear_sfea_ligand = Linear(self.ligand_c_s, self.ligand_c_s)
        self.linear_sfea_receptor = Linear(self.receptor_c_s, self.ligand_c_s)

        self.linear_pfea_ligand = Linear(self.ligand_c_z, self.ligand_c_z)
        self.linear_pfea_receptor = Linear(self.receptor_c_z, self.ligand_c_z)
        self.cross_attn = CrossAttention(self.ligand_c_s)

        if self.pre_layer_norm:
            self.norm_sfea_ligand = nn.LayerNorm(self.ligand_c_s)
            self.norm_pfea_ligand = nn.LayerNorm(self.ligand_c_z)
            self.norm_sfea_receptor = nn.LayerNorm(self.receptor_c_s)
            self.norm_pfea_receptor = nn.LayerNorm(self.receptor_c_z)

    def forward(self, ligand_feat, receptor_feat):
        """
        Args:
            ligand_feat: ligand feat generated by PLM-based model
            receptor_feat: receptor feat generated by MSA-based model

        Returns:
            s: single features (of the ligand-receptor chain complex) of size N x L x c_s
            z: pair features (of the ligand-receptor chain complex) of size N x L x L x c_z
        """
        aa_seq_ligand = ligand_feat['seq']
        aa_seq_receptor = receptor_feat['seq']
        if self.pre_layer_norm:
            ligand_feat['sfea'] = self.norm_sfea_ligand(ligand_feat['sfea'])
            ligand_feat['pfea'] = self.norm_pfea_ligand(ligand_feat['pfea'])
            receptor_feat['sfea'] = self.norm_sfea_receptor(receptor_feat['sfea'])
            receptor_feat['pfea'] = self.norm_pfea_receptor(receptor_feat['pfea'])

        # build initial single features
        sfea_tns = self._get_sfeat(ligand_feat, receptor_feat)
        # build initial pair features
        pfea_tns_lg_lg = self._get_intra_chain_pfea(aa_seq_ligand, ligand_feat, is_ligand=True)
        pfea_tns_rc_rc = self._get_intra_chain_pfea(aa_seq_receptor, receptor_feat, is_ligand=False)
        # zeros init
        pfea_tns_lg_rc, pfea_tns_rc_lg = self._get_inter_chain_pfeat(ligand_feat, receptor_feat)
        pfea_tns = torch.cat([
            torch.cat([pfea_tns_lg_lg, pfea_tns_lg_rc], dim=2),
            torch.cat([pfea_tns_rc_lg, pfea_tns_rc_rc], dim=2),
        ], dim=1)

        return sfea_tns, pfea_tns

    def _get_sfeat(self, ligand_feat, receptor_feat):
        """Get single feature."""
        ls = self.linear_sfea_ligand(ligand_feat['sfea'])
        rs = self.linear_sfea_receptor(receptor_feat['sfea'])
        s = self.cross_attn(ls, rs)
        return s

    def _get_intra_chain_pfea(self, aa_seq, feature, is_ligand=True):
        """Get intra-chain pair features."""
        cord_mat = ProtStruct.get_cb_cords(aa_seq, feature['cord'])
        dist_mat = cdist(cord_mat)
        idxs_mat = torch.clip(torch.floor(
            (dist_mat - self.dist_min) / self.bin_width).to(torch.int64), 0, self.num_bins - 1)
        onht_tns = nn.functional.one_hot(idxs_mat, self.num_bins).unsqueeze(dim=0)
        onht_tns = onht_tns.to(feature['pfea'].dtype)
        if is_ligand:
            pfea_tns = self.linear_pfea_ligand(feature['pfea'])
            pfea_tns += self.linear_dist_ligand(onht_tns)
        else:
            pfea_tns = self.linear_pfea_receptor(feature['pfea'])
            pfea_tns += self.linear_dist_receptor(onht_tns)

        return pfea_tns

    def _get_inter_chain_pfeat(self, ligand_feat, receptor_feat):
        """Get inter-chain pair features."""
        n_resds_ligand = ligand_feat['sfea'].shape[1]
        n_resds_receptor = receptor_feat['sfea'].shape[1]
        device = ligand_feat['sfea'].device
        dtype = ligand_feat['sfea'].dtype
        pfea_tns_lgrc = torch.zeros(
            (1, n_resds_ligand, n_resds_receptor, self.ligand_c_z), dtype=dtype, device=device
        )
        pfea_tns_rclg = pfea_tns_lgrc.transpose(1, 2)
        return pfea_tns_lgrc, pfea_tns_rclg


class MonoToMultimerSM(MonoToMultimerSS):
    """The ligand & receptor to complex conversion network.

    Args:
        ligand_c_s: number of dimensions in single features (c_s)
        ligand_c_z: number of dimensions in pair features (c_z)
        receptor_c_s: umber of dimensions in single feature for receptor (c_s)
        receptor_c_z: number of dimensions in pair feature for receptor (c_z)
        use_icf: use inter-chain interface feature as extra input
    """

    def __init__(
            self,
            ligand_c_s=256,
            ligand_c_z=128,
            receptor_c_s=256,
            receptor_c_z=128,
            num_bins=18,
            dist_min=3.375,
            dist_max=21.375,
            use_icf=False,
            pre_layer_norm=False
    ):
        super().__init__(ligand_c_s, ligand_c_z, receptor_c_s, receptor_c_z,
                         num_bins=num_bins,
                         dist_min=dist_min,
                         dist_max=dist_max,
                         pre_layer_norm=pre_layer_norm)
        self.opm = OuterProductMeanSM(self.ligand_c_s, self.receptor_c_s, self.ligand_c_z)
        self.use_icf = use_icf
        if self.use_icf:
            self.icf_embed_sfea = PPIEmbedding(self.ligand_c_s)
            self.icf_embed_pfea = ContactEmebedding(self.ligand_c_z)

    def forward(self, ligand_feat, receptor_feat, ic_feat=None):
        """
        Args:
            ligand_feat: ligand feat generated by PLM-based model
            receptor_feat: receptor feat generated by MSA-based model

        Returns:
            s: single features (of the ligand-receptor chain complex) of size N x L x c_s
            z: pair features (of the ligand-receptor chain complex) of size N x L x L x c_z
        """
        s, z = super().forward(ligand_feat, receptor_feat)
        if self.use_icf and ic_feat is not None:
            ic_feat = ic_feat.to(s.device)
            # update single and pair features with inter-chain feature
            s += self.icf_embed_sfea(ligand_feat, receptor_feat, ic_feat)
            z += self.icf_embed_pfea(ligand_feat, receptor_feat, ic_feat)

        return s, z

    def _get_sfeat(self, ligand_feat, receptor_feat):
        """Get single feature."""
        ls = self.linear_sfea_ligand(ligand_feat['sfea'])
        rs = self.linear_sfea_receptor(receptor_feat['mfea'][:, 0])
        s = self.cross_attn(ls, rs)
        return s

    def _get_inter_chain_pfeat(self, ligand_feat, receptor_feat):
        """Get inter-chain pair features."""
        pfea_tns_lgrc = self.opm(ligand_feat['sfea'], receptor_feat['mfea'])
        pfea_tns_rclg = pfea_tns_lgrc.transpose(1, 2)

        return pfea_tns_lgrc, pfea_tns_rclg
